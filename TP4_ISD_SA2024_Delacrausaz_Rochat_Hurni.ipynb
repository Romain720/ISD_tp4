{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b123e229",
   "metadata": {},
   "source": [
    "# Introduction à la Science des données\n",
    "\n",
    "\n",
    "## Travail pratique 04 - LVQ et Régression linéaire\n",
    "\n",
    "[Table des matières](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5805e",
   "metadata": {},
   "source": [
    "**Informations de groupe - Prénoms et noms complets:**\n",
    "\n",
    "- Nathanaël Delacrausaz\n",
    "- Axel Rochat\n",
    "- Romain Hurni\n",
    "\n",
    "**Professeurs**: Carlos Peña et Stephan Robert\n",
    "\n",
    "**Assistant(s)**: Thibault Schowing, Arthur Babey, Cédric Campos Carvalho\n",
    "\n",
    "**Contact**: prenom.nom@heig-vd.ch ou de préférence via Teams \n",
    "\n",
    "### Modalités de rendu :\n",
    "\n",
    "- **Date**: <span style=\"background-color:#eebbdd\">19.01.2025, 23h55</span>\n",
    "\n",
    "\n",
    "- **Travail par groupe** de 2 ou 3. \n",
    "\n",
    "\n",
    "- Une fois complété, rendez directement le notebook (fichier avec l'extension _.ipynb_) nommé correctement comme suit <span style=\"background-color:#eebbdd\">\"**TP4_ISD_SA2024_Nom1_Nom2(_Nom3).ipynb**\"</span> en mettant les noms de famille de chaque membres du groupe (pour ceux avec plusieurs noms de famille, vous pouvez mettre juste le premier comme dans l'adresse email). Les TPs rendu avec un fichier mal nommé seront pénalisé !\n",
    "\n",
    "\n",
    "- Mettez vos Prénoms et noms en entier ci-dessus. \n",
    "\n",
    "\n",
    "- Uploadez le fichier complété avant le délais sur Cyberlearn ou Teams selon les consignes données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ad687",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Déroulement et notation\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Les questions</b> sont généralement indiquées en <b>gras</b>, en <span style=\"background-color:#AFEEEE\">bleu</span> ou par une liste d'instructrions et les endroits où répondre sont indiqués par un \"<i>Réponse:</i>\" pour les réponses textuelles. Pour les réponses nécessitant d'écrire du code, les cellules ont déjà été crées et un commentaire indique où/quoi répondre. \n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Notation: </b> Ce TP est noté sur 6 avec un total de  <span style=\"background-color:#eebbdd\"><b>85</b></span> points. Les points sont indiqués pour chaques parties du travail pour un total de <span style=\"background-color:#eebbdd\"><b>78</b></span> points  et <span style=\"background-color:#eebbdd\"><b>7</b></span> points supplémentaires sont attribués au rendu du travail (format et nommage selon les consignes) et à la propreté (lisibilité et mise en page, tournure de phrase des réponses). \n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: </b> Ce notebook vous sera renvoyé via Cyberlearn/Teams ou un autre canal. Les informations principales concernant les corrections seront indiquées après chaque section (banière bleue) avec le nombre de points obtenus. Il est possible que des remarques concernant le code soient directement ajoutées dans celui-ci.\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062f97e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Objectifs </b>\n",
    "</div>\n",
    "\n",
    "- Comprendre la modélisation avec un modèle simple: le modèle à base de règles\n",
    "- Analyse des résultats avec la matrice de confusion\n",
    "- Évaluation des performances avec Validation hold-out et N-Fold Crossvalidation. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aide </b>\n",
    "</div>\n",
    "\n",
    "N'oubliez pas que vous pouvez retourner vers les TPs précédents si vous avez des questions sur Python, Numpy, Pandas ou Matplotlib. Gardez vos cheatsheets à proximité !\n",
    "\n",
    "- [Data wrangling with Pandas](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- [Matplotlib cheatscheets](https://matplotlib.org/cheatsheets/)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>N'hésitez pas à écrire à vos assistants directement sur Teams en cas de question.  </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010106eb",
   "metadata": {},
   "source": [
    "### Table des matières<a name=\"toc\"></a>\n",
    "\n",
    "\n",
    "[Partie 1: LVQ: learning vector quantization ](#Part1)    ----    [28 points](#Part1pts)\n",
    "\n",
    "[- 1.1 Implémentation et interprétation](#Part11)\n",
    "\n",
    "[- 1.2 Questions](#Part12)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "[Partie 2: Régression linéaire ](#Part2)    \n",
    "\n",
    "[- 2.1 California Housing Dataset](#Part21)     ----    [10 points](#Part21pts)\n",
    "\n",
    "[- 2.2 Corrélation, R-carré, variance et covariance](#Part22)     ----    [11 points](#Part22pts)\n",
    "\n",
    "[- 2.3 Régression linéaire simple](#Part23)     ----    [12 points](#Part23pts)\n",
    "\n",
    "[- 2.4 Régression linéaire multiple](#Part24)     ----    [10 points](#Part24pts)\n",
    "\n",
    "[- 2.5 Conclusion](#Part25)     ----    [2 points](#Part25pts)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "[Partie 3: Clustering avec K-means](#Part3)        ----    [5 points](#Part3pts)\n",
    "\n",
    "---\n",
    "\n",
    "<p style=\"background-color:#7ba3e3;padding:10px\"><font size=\"6\"><b></b></font></p>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ae55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from math import sqrt\n",
    "from random import randrange, seed, shuffle\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Différents moyens de standardiser les données mis à disposition par Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, ConfusionMatrixDisplay\n",
    "\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569cb7e",
   "metadata": {},
   "source": [
    "\n",
    "## Partie 1: LVQ: learning vector quantization<a name=\"Part1\"></a>\n",
    "\n",
    "[Table des matières](#toc)\n",
    "\n",
    "[- 1.1 Implémentation et interprétation](#Part11)\n",
    "\n",
    "[- 1.2 Questions](#Part12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15361308",
   "metadata": {},
   "source": [
    "Pour commencer ce TP nous allons reprendre où nous étions au TP précédent et utiliser l’algorithme LVQ pour traiter le problème de classification des vins. Vous allez testez LVQ en explorant différentes valeurs d'hyper-paramètres (c.a.d., nombre de prototypes, learning rate et nombre d’epochs). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdabbe",
   "metadata": {},
   "source": [
    "<a name=\"Part11\"></a>\n",
    "### 1.1 Implémentation et interprétation\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Complétez les commentaires</p>(7 points)\n",
    "\n",
    "Pour commencer complétez les docstrings des fonctions de l'implémentation de LVQ ci-dessous. Ce code provient du cours et a simplement été adapté pour le dataset wines avec la cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002321cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(row1: list, row2: list):\n",
    "    '''\n",
    "    Calcule la distance euclidienne entre deux vecteurs de caractéristiques.\n",
    "    \n",
    "    Args:\n",
    "        row1 (list): Premier vecteur de caractéristiques.\n",
    "        row2 (list): Deuxième vecteur de caractéristiques.\n",
    "    \n",
    "    Returns:\n",
    "        float: La distance euclidienne entre les deux vecteurs.\n",
    "    '''\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "\n",
    "def get_best_matching_unit(codebook: list, test_row: list):\n",
    "    '''\n",
    "    Trouve le vecteur de code le plus proche (BMU) dans le codebook pour une ligne de test donnée.\n",
    "    \n",
    "    Args:\n",
    "        codebook (list): Liste des vecteurs de code.\n",
    "        test_row (list): Vecteur de caractéristiques de la ligne de test.\n",
    "    \n",
    "    Returns:\n",
    "        list: Le vecteur de code le plus proche.\n",
    "    '''\n",
    "    distances = list()\n",
    "    for codevector in codebook:\n",
    "        dist = euclidean_distance(codevector, test_row)\n",
    "        distances.append((codevector, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    return distances[0][0]\n",
    "\n",
    "\n",
    "def predict(codebooks: list, test_row: list):\n",
    "    '''\n",
    "    Prédit la classe pour une ligne de test donnée en utilisant les vecteurs de code.\n",
    "    \n",
    "    Args:\n",
    "        codebooks (list): Liste des vecteurs de code.\n",
    "        test_row (list): Vecteur de caractéristiques de la ligne de test.\n",
    "    \n",
    "    Returns:\n",
    "        int: La classe prédite pour la ligne de test.\n",
    "    '''\n",
    "    bmu = get_best_matching_unit(codebooks, test_row)\n",
    "    return bmu[-1]\n",
    "\n",
    "\n",
    "def predict_lvq(train, test, n_codebooks, lrate, epochs):\n",
    "    '''\n",
    "    Prédit les classes pour un ensemble de test en utilisant l'algorithme LVQ.\n",
    "    \n",
    "    Args:\n",
    "        train (list): Ensemble d'entraînement.\n",
    "        test (list): Ensemble de test.\n",
    "        n_codebooks (int): Nombre de vecteurs de code.\n",
    "        lrate (float): Taux d'apprentissage.\n",
    "        epochs (int): Nombre d'époques d'entraînement.\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des classes prédites pour l'ensemble de test.\n",
    "    '''\n",
    "    codebooks = train_codebook(train, n_codebooks, lrate, epochs)\n",
    "    return [predict(codebooks, row) for row in test]\n",
    "\n",
    "\n",
    "def init_codevector(train, category):\n",
    "    '''\n",
    "    Initialise un vecteur de code pour une catégorie donnée en sélectionnant une observation aléatoire de cette catégorie.\n",
    "    \n",
    "    Args:\n",
    "        train (list): Ensemble d'entraînement.\n",
    "        category (int): Catégorie pour laquelle initialiser le vecteur de code.\n",
    "    \n",
    "    Returns:\n",
    "        list: Vecteur de code initialisé.\n",
    "    '''\n",
    "    n_records = len(train)\n",
    "    n_features = len(train[0])-1\n",
    "    found = False\n",
    "    while(not found):\n",
    "        random_observation = randrange(n_records)\n",
    "        if (train[random_observation][-1] == category):\n",
    "            found = True\n",
    "            \n",
    "    codevector = [train[random_observation][i] for i in range(n_features)]\n",
    "    codevector.append(category)\n",
    "    return codevector\n",
    "\n",
    "\n",
    "def random_codebook(train):\n",
    "    '''\n",
    "    Génère un vecteur de code aléatoire à partir de l'ensemble d'entraînement.\n",
    "    \n",
    "    Args:\n",
    "        train (list): Ensemble d'entraînement.\n",
    "    \n",
    "    Returns:\n",
    "        list: Vecteur de code aléatoire.\n",
    "    '''\n",
    "    n_records = len(train)\n",
    "    n_features = len(train[0])\n",
    "    codebook = [train[randrange(n_records)][i] for i in range(n_features)]\n",
    "    return codebook\n",
    "\n",
    "\n",
    "def train_codebook(train, n_codevectors, lrate, epochs):\n",
    "    '''\n",
    "    Entraîne les vecteurs de code en utilisant l'algorithme LVQ.\n",
    "    \n",
    "    Args:\n",
    "        train (list): Ensemble d'entraînement.\n",
    "        n_codevectors (int): Nombre de vecteurs de code.\n",
    "        lrate (float): Taux d'apprentissage.\n",
    "        epochs (int): Nombre d'époques d'entraînement.\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des vecteurs de code entraînés.\n",
    "    '''\n",
    "    codebook = [random_codebook(train) for i in range(n_codevectors)]\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0-(epoch/float(epochs)))\n",
    "        sum_error = 0.0\n",
    "        shuffle(train)\n",
    "        for row in train:\n",
    "            bmu = get_best_matching_unit(codebook, row)\n",
    "            for i in range(len(row)-1):\n",
    "                error = row[i] - bmu[i]\n",
    "                sum_error += error**2\n",
    "                if bmu[-1] == row[-1]:\n",
    "                    bmu[i] += rate * error\n",
    "                else:\n",
    "                    bmu[i] -= rate * error\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, rate, sum_error))\n",
    "    return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21500287",
   "metadata": {},
   "source": [
    "Fonctions reprises de kNN du TP précédent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual: list[float], predicted: list[float]):\n",
    "    \"\"\"\n",
    "    Calcule l'accuracy en comparant les valeurs réelles et prédites.\n",
    "\n",
    "    Args:\n",
    "        actual (list[float]): Liste des valeurs réelles.\n",
    "        predicted (list[float]): Liste des valeurs prédites.\n",
    "\n",
    "    Returns:\n",
    "        float: Le pourcentage d'accuracy.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    \"\"\"\n",
    "    Divise le dataset en n_folds parties pour la validation croisée.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): Le dataset à diviser.\n",
    "        n_folds (int): Le nombre de folds à créer.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste de n_folds sous-ensembles du dataset.\n",
    "    \"\"\"\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702f14a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Testez différents hyper paramètres.</p>(3 points)\n",
    "\n",
    "Trouvez des paramètres permettant d'arriver à une accuracy de plus de 96%. \n",
    "\n",
    "Notes: \n",
    "- L'accuracy et la matrice de confusion sont affiché en fin de sortie\n",
    "- pour éviter un affichage trop long, vous pouvez soit: réduire la cellule de sortie en cliquant à gauche de la cellule, soit décommenter le *print()* de la fonction *train_codebook()*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae957d9-a1b2-4f62-891c-c5eb53650133",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Note', 'Alcool', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', \n",
    "           'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', \n",
    "           'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "wines = pd.read_csv('./wine.data', names=headers)\n",
    "\n",
    "# Le code ci-dessus attend la variable dépendante (Note) à la fin et non au début\n",
    "# Quelques modifications s'imposent. \n",
    "\n",
    "# On garde le même scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Créer une copie et prendre une liste des colonnes des données indépendantes (entrées)\n",
    "df_normalized_end = wines.copy()\n",
    "cols = wines.columns[wines.columns != 'Note']\n",
    "\n",
    "# Remplacer les colonnes des données par les données transformées\n",
    "df_normalized_end[cols] = scaler.fit_transform(df_normalized_end[cols])\n",
    "\n",
    "# On prend la liste des colonnes et on met le premier élément à la fin\n",
    "all_cols = df_normalized_end.columns.tolist()\n",
    "\n",
    "all_cols = all_cols[1:] + [all_cols[0]]\n",
    "print(f\"Nouvel ordre des colonnes: {all_cols}\")\n",
    "\n",
    "df_normalized_end = df_normalized_end[all_cols]\n",
    "\n",
    "# conversion en liste de listes \n",
    "data_normalized_end = df_normalized_end.values.tolist()\n",
    "\n",
    "seed(0)    # Fix pseudo aléatoire\n",
    "\n",
    "# Hyper paramètres de LVQ à optimiser. \n",
    "\n",
    "lr = 0.01\n",
    "n_epochs = 200\n",
    "n_codevectors = 10\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "folds = cross_validation_split(data_normalized_end, n_folds=5)\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "results = defaultdict(list)\n",
    "    \n",
    "for test_i in range(len(folds)):\n",
    "    \n",
    "    train = list(itertools.chain.from_iterable(folds[:test_i] + folds[test_i+1:]))\n",
    "    test = folds[test_i]\n",
    "    \n",
    "    predictions += predict_lvq(train, test, n_codevectors, lr, n_epochs)\n",
    "    actuals += [i[-1] for i in test]\n",
    "    print(f'Prediction of fold {test_i}: {accuracy_metric(actuals, predictions)}')\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "results = accuracy_metric(actuals, predictions)\n",
    "print(f'Performance of LVQ with ({lr=}, {n_epochs=}, {n_codevectors=}): {results}')\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(actuals, predictions)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels = [\"1\", \"2\", \"3\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a720b4b",
   "metadata": {},
   "source": [
    "<a name=\"Part12\"></a>\n",
    "### 1.2 Questions\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "**Répondez aux questions suivantes** (16 points) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e3be",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Comparez les prédictions de LVQ obtenues ici et les prédictions que vous avez obtenu avec kNN au TP précédent. </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b569a1",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "Avec le KNN la précision était de 90% et avec LVQ 96% donc LVQ est plus prcis que KNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d43e93",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Donnez les différences entre kNN et LVQ au niveau de la nature de l'algorithme, de la phase d'apprentissage, de la représentation des classes, de la sensibilité au bruit et de la complexité. Faites une liste à puce. </p> (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3414cd",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    " \n",
    "- Nature de l'algorithme :\n",
    "\n",
    "  kNN : Algorithme paresseux (lazy learning), il ne construit pas de modèle explicite pendant la phase d'entraînement.\n",
    "\n",
    "  LVQ : Algorithme actif (eager learning), il construit un modèle explicite en ajustant les vecteurs de code pendant  la phase d'entraînement.\n",
    "\n",
    "- Phase d'apprentissage :\n",
    "\n",
    "    kNN : Pas de phase d'apprentissage explicite. L'algorithme stocke simplement les données d'entraînement et effectue les calculs lors de la prédiction.\n",
    "\n",
    "    LVQ : Phase d'apprentissage explicite où les vecteurs de code sont ajustés pour mieux représenter les classes.\n",
    "\n",
    "- Représentation des classes :\n",
    "\n",
    "    kNN : Les classes sont représentées par les instances d'entraînement elles-mêmes.\n",
    "\n",
    "    LVQ : Les classes sont représentées par des vecteurs de code (prototypes) qui sont ajustés pendant l'entraînement.\n",
    "\n",
    "- Sensibilité au bruit :\n",
    "\n",
    "    kNN : Sensible au bruit car chaque instance d'entraînement peut influencer les prédictions.\n",
    "\n",
    "    LVQ : Moins sensible au bruit car les vecteurs de code sont ajustés pour minimiser l'impact des instances bruyantes.\n",
    "\n",
    "- Complexité :\n",
    "\n",
    "    kNN : Complexité de prédiction élevée (O(n)) car il doit calculer la distance entre l'instance de test et toutes les instances d'entraînement.\n",
    "\n",
    "    LVQ : Complexité de prédiction plus faible (O(m), où m est le nombre de vecteurs de code) car il ne compare qu'avec les vecteurs de code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ea3f0",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Qu'est-ce que l'aléatoire et le pseudo-aléatoire ? </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb3395",
   "metadata": {},
   "source": [
    "*Réponse:* l'aléatoire est vraiment imprévisible, tandis que le pseudo-aléatoire est déterminé par des formules mathématiques et peut être recréé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a138e",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Que se passe-t-il si vous ne fixer par le seed, et quel risque cela représente ? Quelles fonctions, dans l'implémentation de LVQ de ce TP, utilisent du pseudo-aléatoire ?</p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28da9b",
   "metadata": {},
   "source": [
    "*Réponse:* \n",
    "Si on ne fixe pas le seed, les résultats de notre algorithme peuvent varier à chaque exécution, rendant difficile la reproduction des résultats et la comparaison des modèles.\n",
    "\n",
    "Fonctions utilisant du pseudo-aléatoire dans l'implémentation de LVQ :\n",
    "\n",
    "init_codevector(train, category): Sélectionne une observation aléatoire pour initialiser un vecteur de code.\n",
    "\n",
    "random_codebook(train): Génère un vecteur de code aléatoire à partir de l'ensemble d'entraînement.\n",
    "\n",
    "train_codebook(train, n_codevectors, lrate, epochs): Mélange les données d'entraînement à chaque époque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9c7e9",
   "metadata": {},
   "source": [
    "<a name=\"Part1pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 1: </b> Points obtenus: /28\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "- Docstrings: /7\n",
    "- Hyper-paramètres: /3\n",
    "- Questions: /16\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e09b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<p style=\"background-color:#7ba3e3;padding:10px\"><font size=\"6\"><b></b></font></p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b4d61",
   "metadata": {},
   "source": [
    "## Partie 2 - Régression linéaire<a name=\"Part2\"></a>\n",
    "\n",
    "[Table des matières](#toc)\n",
    "\n",
    "[- 2.1 California Housing Dataset](#Part21)     ----    [10 points](#Part21pts)\n",
    "\n",
    "[- 2.2 Corrélation, R-carré, variance et covariance](#Part22)     ----    [11 points](#Part22pts)\n",
    "\n",
    "[- 2.3 Régression linéaire simple](#Part23)     ----    [12 points](#Part23pts)\n",
    "\n",
    "[- 2.4 Régression linéaire multiple](#Part24)     ----    [10 points](#Part24pts)\n",
    "\n",
    "[- 2.5 Conclusion](#Part25)     ----    [2 points](#Part25pts)\n",
    "\n",
    "Comme vous avez pu en voir au cours des précédents travaux pratiques, une certaine quantité de datasets publics sont régulièrement utilisés comme base d'apprentissage pour la science des données. Dans ce TP nous utiliserons le dataset connu sous le nom de \"California Housing Dataset\" qu'il est possible d'obtenir [ici via scikit-learn](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html) et qui contient des données concernant le prix des maisons en Californie. Scikit-learn fournit une rapide analyse exploratoire qui a été copiée en partie ci-dessous. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7028eb",
   "metadata": {},
   "source": [
    "<a name=\"Part21\"></a>\n",
    "### 2.1 California Housing Dataset\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "\n",
    "**Regardez l'analyse exploratoire des données présentée ci-dessous et répondez aux [questions](#Q21).**\n",
    "\n",
    "Vous n'avez normalement pas besoin de modifier le code mais vous êtes libres d'en ajouter ou de le modifier. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebe053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la fonction fetch_california_housing\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Et on l'utilise. \n",
    "# l'option \"as_frame\" permet d'obtenir directement un DataFrame dans le dictionnaire.\n",
    "# Sans cela, l'élément \"frame\" serait absent du dictionnaire ci-dessous.\n",
    "# Les différents éléments du dictionnaire (Data, Target, DESCR, noms de colonnes, etc) \n",
    "# sont dès lors directement accessible\n",
    "\n",
    "california_housing = fetch_california_housing(as_frame=True) \n",
    "\n",
    "# Étant donné qu'il s'agit d'un dictionnaire, on peut regarder les clés et leur contenu (affiché ci-dessus)\n",
    "california_housing.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ec5a6",
   "metadata": {},
   "source": [
    "Notre variable \"california_housing\" contient donc:\n",
    "\n",
    "- **Data:** tableau des données principales sans la variable dépendante <class 'pandas.core.frame.DataFrame'>\n",
    "- **Target:** données de la variable dépendante <class 'pandas.core.series.Series'>\n",
    "- **Frame:** le dataframe obtenu grâce à l'option \"as_frame = True\" <class 'pandas.core.frame.DataFrame'>\n",
    "- **feature_names:** nom(s) de colonne pour variable(s) indépendante(s) <class 'list'>\n",
    "- **target_names:** nom(s) de colonne pour variable(s) dépendante(s) <class 'list'>\n",
    "- **DESCR:** description du dataset <class 'str'>\n",
    "\n",
    "\n",
    "En utilisant print(), on peut afficher de manière plus lisible l'élément \"DESCR\" du dictionnaire. (car print() va interpréter les caractères spéciaux comme '\\n' -> retour à la ligne)\n",
    "\n",
    "**Lisez attentivement le contenu de DESCR ci-dessous:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(california_housing[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0395995",
   "metadata": {},
   "source": [
    "---\n",
    "En accédant à l'élément frame, on peut commencer à travailler comme d'habitude et analyser nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données brutes\n",
    "df_raw = california_housing.frame\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des variables\n",
    "df_raw.hist(figsize=(12, 10), bins=30, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot des variables\n",
    "\n",
    "variables = df_raw.columns\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20, 20))\n",
    "axs = axs.flatten()\n",
    "for i, col in enumerate(variables):\n",
    "    df_raw.boxplot(col, ax=axs[i])\n",
    "    \n",
    "fig.suptitle('Boxplot of some of the variables', fontsize=16)    \n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eee18f",
   "metadata": {},
   "source": [
    "Certaines variables présentent des valeurs extrêmes. Observons les en détails:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_interest = [\"AveRooms\", \"AveOccup\", \"Population\"] \n",
    "california_housing.frame[features_of_interest].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f368b0e",
   "metadata": {},
   "source": [
    "Pour avoir un meilleur aperçu des données, nous allons supprimer quelques observations extrêmes. Pour prédire le prix d'une maison à partir de données régionales, nous pouvons exclure les éléments sortants de l'ordinaire. Si vous le souhaitez, vous pouvez réafficher différents graphiques pour voir vos nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cdbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un nouveau DataFrame \"df\" sans les valeurs abérrantes\n",
    "df = df_raw[(df_raw[\"AveRooms\"] < 10) & (df_raw[\"Population\"] < 20000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af6e55",
   "metadata": {},
   "source": [
    "<a name=\"plotA\"></a>\n",
    "\n",
    "**Ho non !** Le code ci-dessous affiche un magnifique graphique, mais on ne comprend rien au code ! Complétez les 10 commentaires indiqués par \"# -\". \n",
    "\n",
    "Complémentez vos commentaires directement dans le code ci-dessous. Il n'y a rien besoin de reporter dans la [première question](#Q21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1199de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser un générateur de nombres aléatoires avec une graine fixe pour la reproductibilité\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# Sélectionner aléatoirement 10 000 indices uniques à partir des indices du DataFrame\n",
    "indices = rng.choice(np.arange(df.shape[0]), \n",
    "                     size=10000,\n",
    "                     replace=False)\n",
    "\n",
    "# Créer un graphique de dispersion avec les données sélectionnées\n",
    "sns.scatterplot(\n",
    "    data=df.iloc[indices],                         # Utiliser les lignes sélectionnées du DataFrame\n",
    "    x=\"Longitude\", y=\"Latitude\",                   # Définir les axes x et y\n",
    "    size=\"MedHouseVal\",                            # Définir la taille des points en fonction de la valeur médiane des maisons\n",
    "    hue=\"MedHouseVal\",                             # Définir la couleur des points en fonction de la valeur médiane des maisons\n",
    "    palette=\"viridis\",                             # Utiliser la palette de couleurs 'viridis'\n",
    "    alpha=0.5)                                     # Définir la transparence des points\n",
    "\n",
    "# Ajouter une légende avec le titre \"MedHouseVal\" et positionner la légende en dehors du graphique\n",
    "plt.legend(title=\"MedHouseVal\", bbox_to_anchor=(1.05, 1),\n",
    "           loc=\"upper left\")\n",
    "# Ajouter un titre au graphique\n",
    "_ = plt.title(\"Median house value depending of\\n their spatial location\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2066d8f",
   "metadata": {},
   "source": [
    "<a name=\"plotB\"></a>\n",
    "On créé maintenant un joli pairplot avec Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inutile de garder ces deux colonnes\n",
    "columns_drop = [\"Longitude\", \"Latitude\"]\n",
    "subset = df.iloc[indices].drop(columns=columns_drop)\n",
    "\n",
    "# Ignorez ce petit passage un peu complexe, c'est pour avoir 6 couleurs pour une variable continue. \n",
    "# Quantize the target and keep the midpoint for each interval\n",
    "subset[\"MedHouseVal\"] = pd.qcut(subset[\"MedHouseVal\"], 6, retbins=False)\n",
    "subset[\"MedHouseVal\"] = subset[\"MedHouseVal\"].apply(lambda x: x.mid)\n",
    "_ = sns.pairplot(data=subset, hue=\"MedHouseVal\", palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef596aa",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2362b6",
   "metadata": {},
   "source": [
    "<a name=\"Q21\"></a>\n",
    "\n",
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae26ef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Complétez les commentaires du graphique de la représentation spatiale des points ci-dessus.</p> (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f090f",
   "metadata": {},
   "source": [
    "**Indiquez vos réponses directement dans le code du [graphique](#plotA)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8666a30",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Donnez une description de ce qui peut être observé sur le pairplot. Est-ce un bon graphique ? Quelle amélioration(s) pourrai(en)t être apportée(s) ou quel autre graphique pourrait être ajouté ?</p>(3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16749c60",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "L'image montre un pairplot, qui est un graphique de paires de variables. Chaque sous-graphe représente une combinaison de deux variables différentes, avec des histogrammes sur la diagonale montrant la distribution de chaque variable. Les variables représentées sont \"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", et \"AveOccup\". Les points sont colorés en fonction de la variable \"MedHouseVal\", avec une légende indiquant différentes valeurs de \"MedHouseVal\" par des couleurs allant du bleu au vert.\n",
    "\n",
    "Ce pairplot permet d'observer les relations entre les différentes variables. Par exemple, on peut voir comment \"MedInc\" est corrélé avec \"HouseAge\", \"AveRooms\", etc. Les histogrammes sur la diagonale montrent la distribution de chaque variable individuelle.\n",
    "\n",
    "**Oui, c'est un bon graphique** pour explorer les relations entre plusieurs variables simultanément. Il permet de visualiser les corrélations et les distributions de manière compacte.\n",
    "\n",
    "**Améliorations possibles :**\n",
    "- Ajouter des titres et des labels plus descriptifs pour chaque axe afin de rendre le graphique plus compréhensible.\n",
    "\n",
    "- Les couleurs utilisées pour \"MedHouseVal\" pourraient être plus distinctes pour faciliter la différenciation des valeurs.\n",
    "\n",
    "- Ajouter des lignes de tendance ou des courbes de régression pour mieux visualiser les relations entre les variables.\n",
    "\n",
    "- Filtrer les données pour éliminer les valeurs aberrantes qui peuvent rendre les relations moins claires.\n",
    "\n",
    "**Autres graphiques possibles :**\n",
    "- Une heatmap montrant les coefficients de corrélation entre les variables pourrait compléter ce pairplot en fournissant une vue d'ensemble des relations linéaires.\n",
    "\n",
    "- Des graphiques de régression pour chaque paire de variables pourraient aider à comprendre les relations plus en détail.\n",
    "\n",
    "- Des boxplots pour chaque variable pourraient aider à visualiser la distribution et les valeurs aberrantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97f469",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quelle(s) variable(s) se démarquent des autres en tant que potentiel(s) prédicteur(s) et à quoi le voit-on sur le pairplot ? </p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8768f30",
   "metadata": {},
   "source": [
    "*Réponse:* \"MedInc\" se démarque clairement comme un prédicteur potentiel fort de \"MedHouseVal\", suivi par \"HouseAge\" et \"AveRooms\". Ces observations sont basées sur les alignements et les tendances visibles dans les sous-graphes du pairplot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76dea89",
   "metadata": {},
   "source": [
    "<a name=\"Part21pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.1: </b> Points obtenus: /10\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117005ef",
   "metadata": {},
   "source": [
    "<a name=\"Part22\"></a>\n",
    "### 2.2 Corrélation, R-carré, variance et covariance\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3780f64",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons rapidement revoir des concepts qui sont très souvent mélangés. Pour une explication limpide, dans un anglais très compréhensible et sous-titré, vous pouvez regarder les vidéos suivantes (attention, contient de l'humour et de la guitare). Ces vidéos paraissent longues mais vont à un rythme relativement lent, n'hésitez pas à simplement revoir les passages qui vous sont utiles: \n",
    "\n",
    "\n",
    "- [Correlation Clearly Explained !!!(20 minutes)](https://www.youtube.com/watch?v=xZ_z8KWkhXE)\n",
    "- [Calculating the Mean, Variance and Standard Deviation, Clearly Explained!!!](https://www.youtube.com/watch?v=SzZ6GpcfoQY)\n",
    "- [Covariance, Clearly Explained !!!(20 minutes)](https://www.youtube.com/watch?v=qtaqvPAeEJY)\n",
    "- [R-Squared, Clearly Explained !!!(11 minutes)](https://www.youtube.com/watch?v=bMccdk8EdGo)\n",
    "- [Linear Regression, Clearly Explained !!!(30 minutes)](https://www.youtube.com/watch?v=nk2CQITm_eo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d238b",
   "metadata": {},
   "source": [
    "Voici les éléments principaux à reconnaitre:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bb652",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Moyenne, variance et écart-type :**\n",
    "   - Moyenne ($\\bar{x}$) : $$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n",
    "   - Variance ($\\sigma^2$) : $$\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$$\n",
    "   - Écart-type ($\\sigma$) : $$\\sigma = \\sqrt{\\sigma^2}$$\n",
    "\n",
    "2. **Covariance :**\n",
    "   - Covariance ($\\text{cov}(X, Y)$) : $$\\text{cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "3. **Coefficient de corrélation de Bravais-Pearson :**\n",
    "   - Coefficient de corrélation ($r$) : $$r = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    "4. **R-squared (coefficient de détermination de Pearson) :**\n",
    "   - Coefficient de détermination ($R^2$) : $$R^2 = r^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a7558",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "La formule pour $( R^2 )$ peut donc être donnée par:\n",
    "\n",
    "$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "\n",
    "Avec:\n",
    "- $ y_i $ valeur observée de la variable dépendante.\n",
    "- $ \\hat{y}_i $ valeur prédite de la variable dépendante.\n",
    "- $ \\bar{y} $ moyenne des valeur observée de la variable dépendante.\n",
    "- $ n $ nombre d'observations du dataset. \n",
    "\n",
    "Cette formule calcule $ R^2 $ en comparant la \"sum of squared errors\" du modèle de régression (en anglais: sum of squared residuals, $ \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $ sur le total des carrés des écarts à la moyenne $\\sum_{i=1}^{n} (y_i - \\bar{y})^2 $.\n",
    "\n",
    "**C'est la formule que vous avez dans le cours.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df9bae",
   "metadata": {},
   "source": [
    "---\n",
    "Pour calculer le score $R^2$ on peut utiliser la fonction *r2_score()* fourni par scikit-learn ou l'écrire nous-même. Pour la beauté du geste, et quelques points bien sûr: \n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> complétez la fonction ci-dessous pour calculer le coefficient $R^2$. N'oubliez pas d'écrire la docstring correctement avec une description de la fonction et de son utilité et des paramètres.</p>\n",
    "\n",
    "\n",
    "(5 points)\n",
    "\n",
    "\n",
    "Pour être certain que votre code fonctionne, vous pouvez exécuter la cellule de TEST qui comparera les résultats de votre méthode avec ceux de la méthode préfaite de sklearn. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Complétez le code et la docstring pour calculer R-carré - \n",
    "# - (n'oubliez pas de changer la valeur de retour !)\n",
    "\n",
    "def pearson(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calcule le coefficient de détermination R² (coefficient de corrélation au carré) pour évaluer\n",
    "    la qualité des prédictions d'un modèle de régression.\n",
    "\n",
    "    Paramètres:\n",
    "    y : array-like de taille (n,)\n",
    "        Les valeurs observées (valeurs réelles) de la variable dépendante.\n",
    "    y_pred : array-like de taille (n,)\n",
    "        Les valeurs prédites par le modèle de régression.\n",
    "\n",
    "    Retourne:\n",
    "    float\n",
    "        Le coefficient R², une valeur entre 0 et 1.\n",
    "    \"\"\"\n",
    "    # Calcul de la moyenne des valeurs observées\n",
    "    y_mean = sum(y) / len(y)\n",
    "\n",
    "    # Somme des carrés des résidus (SS_residual)\n",
    "    ss_residual = sum((observed - predicted) ** 2 for observed, predicted in zip(y, y_pred))\n",
    "\n",
    "    # Somme totale des carrés (SS_total)\n",
    "    ss_total = sum((observed - y_mean) ** 2 for observed in y)\n",
    "\n",
    "    # Calcul de R²\n",
    "    r_squared = 1 - (ss_residual / ss_total)\n",
    "    return r_squared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Affiche un message en cas de réussite / échec de la méthode \"pearson()\"\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "y = np.random.randint(20, size=10)\n",
    "y_pred = np.random.randint(20, size=10)\n",
    "if (round(pearson(y, y_pred), 3) == round(r2_score(y, y_pred), 3)): \n",
    "    print(f\"RÉUSSITE - La fonction pearson() donne le résultat attendu.\")\n",
    "else:\n",
    "    print(f\"ÉCHEC - Il semble qu'il y ait une erreur et que votre fonction ne donne pas les bons résultats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb6678",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"plotC\"></a>\n",
    "**Coefficient de corrélation de Bravais-Pearson**\n",
    "\n",
    "Lorsque nos données contiennent beaucoup de variables, il peut être utile de savoir si elles sont corrélées entre elles. Pour avoir un rappel visuel sur ce qu'est la corrélation linéaire et quelles en sont les plages de valeurs, vous pouvez rapidement regarder [les exemples graphiques donnés sur la page Wikipédia concernée](https://fr.wikipedia.org/wiki/Corr%C3%A9lation_(statistiques)).\n",
    "\n",
    "Nous vous donnons ci-dessous la matrice de corrélation joliement affichée avec Seaborn. Si les valeurs des corrélations ne s'affichent pas dans chaque tuile, vous pouvez essayer de mettre à jour Seaborn dans votre environnement.\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Dans la cellule de réponse, décrivez les corrélations demandées. Ont-elles un sens ? </p> (6 points)\n",
    "\n",
    "Pour vous aider à visualiser les données pour interpréter ces corrélations, vous pouvez toujours retourner voir le [scatterplot](#plotB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de la matrice de corrélation.\n",
    "\n",
    "# Masque pour la partie supérieure de la matrice, qui est symétrique. \n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "\n",
    "# Figure et plot\n",
    "fig, ax = plt.subplots(figsize=(15,12)) \n",
    "dataplot = sns.heatmap(df.corr(), mask=mask, cmap=\"YlGnBu\", annot=True)\n",
    "plt.yticks(rotation=45) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d635d19",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "- **MedInc vs AveRooms:** Corrélation positive forte (0.67). Les revenus plus élevés sont associés à des logements plus grands avec plus de pièces.\n",
    "\n",
    "- **MedInc vs MedHouseVal:** Corrélation positive forte (0.69). Les revenus plus élevés sont liés à des maisons plus chères.\n",
    "\n",
    "- **AveRooms vs MedHouseVal:** Corrélation positive modérée (0.33). Plus de pièces en moyenne est associé à une valeur de maison plus élevée.\n",
    "\n",
    "- **Longitude vs Latitude:** Corrélation négative très forte (-0.93). Cela montre une orientation géographique marquée.\n",
    "\n",
    "- **AveRooms vs AveBedrooms:** Corrélation positive faible (0.22). Plus de pièces entraîne en général légèrement plus de chambres.\n",
    "\n",
    "- **Population vs HouseAge:** Corrélation négative modérée (-0.31). Les zones densément peuplées ont tendance à avoir des logements plus récents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e0059e",
   "metadata": {},
   "source": [
    "<a name=\"Part22pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.2: </b> Points obtenus: /11\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f0af3",
   "metadata": {},
   "source": [
    "<a name=\"Part23\"></a>\n",
    "### 2.3 Régression linéaire simple \n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Attention: </b> la régression linéaire dans cet exercice peut prendre environ 5 minutes avec les hyper-paramètres actuels. \n",
    "</div>\n",
    "\n",
    "Maintenant que vous êtes familiarisés avec la base de données, vous allez utiliser l'algorithme de régression linéaire simple vu en classe. \n",
    "\n",
    "Si vous voulez revoir comment fonctionne la régression linéaire il y a toujours [la vidéo de StatQuest](https://www.youtube.com/watch?v=nk2CQITm_eo) qui revoit étape par étape le fonctionnement de la régression simple et de l'ajustement d'une ligne aux données, de $ R^2 $ et de la régression multiple (en Anglais simple et clair mais quand même en 25 minutes, **les premières 10 minutes suffisent**). [Cette vidéo \"The Main Ideas of Fitting a Line to Data\"](https://www.youtube.com/watch?v=PaFPbb66DxQ) vous résume en moins de temps le concept qui va être utilisé dans le code ci-dessous: comment ajuster une ligne aux données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf8f4",
   "metadata": {},
   "source": [
    "**Les troix méthodes ci-dessous: \"*compute_MSE*\", \"*step_gradient*\" et \"*gradient_descent*\" n'ont pas de commentaire d'entête.** \n",
    "\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Complétez les docstrings en indiquant ce que fait la fonction et pourquoi, ce que l'on a comme paramètres et ce qu'elle retourne.</p>\n",
    "(6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65279257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MSE(b,m,data):\n",
    "    \"\"\"\n",
    "    Calcule l'erreur quadratique moyenne pour un modèle de régression linéaire.\n",
    "\n",
    "    Paramètres:\n",
    "    - b : float   L'ordonnée à l'origine (intercept) de la droite de régression.  \n",
    "    - m : float   La pente (coefficient directeur) de la droite de régression.  \n",
    "    - data : array-like  \n",
    "        Un tableau contenant les points de données où la première colonne est la variable indépendante (x) \n",
    "        et la deuxième colonne est la variable dépendante (y).  \n",
    "\n",
    "    Retourne:\n",
    "    - float  La valeur de l'erreur quadratique moyenne pour les paramètres donnés.  \n",
    "    \"\"\"\n",
    "    totalError = 0\n",
    "    for i in range (0, len(data)):\n",
    "        x = data[i, 0] # variable indépendante\n",
    "        y = data[i, 1] # variable dépendante\n",
    "        totalError += (y-(m*x + b)) ** 2 \n",
    "    return totalError/ float(len(data))  \n",
    "\n",
    "def step_gradient(b_current, m_current, data, learning_rate):\n",
    "    \"\"\"\n",
    "    Effectue une itération de la descente de gradient pour ajuster les paramètres d'une régression linéaire.\n",
    "\n",
    "    Paramètres:\n",
    "    - b_current : float  Valeur actuelle de l'ordonnée à l'origine \n",
    "    - m_current : float  Valeur actuelle de la pente  \n",
    "    - data : array-like  \n",
    "        Un tableau contenant les points de données où la première colonne est la variable indépendante (x) et la deuxième colonne est la variable dépendante (y).  \n",
    "    - learning_rate : float   Taux d'apprentissage déterminant la taille du pas de mise à jour des paramètres.  \n",
    "\n",
    "    Retourne:\n",
    "    - list : [new_b, new_m]  Les nouvelles valeurs de l'ordonnée à l'origine et de la pente après mise à jour.  \n",
    "    \"\"\"\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(data))\n",
    "    for i in range(0, len(data)):\n",
    "        x = data[i, 0]\n",
    "        y = data[i, 1]\n",
    "        b_gradient += -(1/N) * (y - (m_current * x + b_current))\n",
    "        m_gradient += -(1/N) * x * (y - (m_current * x + b_current))\n",
    "        \n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return [new_b, new_m]\n",
    "\n",
    "def gradient_descent(data, starting_b, starting_m, learning_rate, num_epochs, verbose=False):\n",
    "    \"\"\"\n",
    "    Implémente la descente de gradient pour optimiser les paramètres d'une régression linéaire.\n",
    "\n",
    "    Paramètres:\n",
    "    - data : array-like  \n",
    "        Un tableau contenant les points de données où la première colonne est la variable indépendante (x)  et la deuxième colonne est la variable dépendante (y).  \n",
    "    - starting_b : float  Valeur initiale de l'ordonnée à l'origine (intercept).  \n",
    "    - starting_m : float  Valeur initiale de la pente (coefficient directeur).  \n",
    "    - learning_rate : float  Taux d'apprentissage qui contrôle la taille des mises à jour des paramètres.  \n",
    "    - num_epochs : int  Nombre d'itérations (ou époques) pour la descente de gradient.  \n",
    "    - verbose : bool, optionnel (par défaut False)  Si True, affiche les paramètres mis à jour et l'erreur après chaque itération.  \n",
    "\n",
    "    Retourne:\n",
    "    - list : [b, m]  Les valeurs finales optimisées de l'ordonnée à l'origine et de la pente.  \n",
    "    \"\"\"\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_epochs):\n",
    "        b,m = step_gradient(b, m, np.array(data), learning_rate)\n",
    "        if verbose:\n",
    "            print(\"After {0} epochs b = {1}, m = {2}, error = {3}\".format(i, b, m, compute_MSE(b, m, data)))\n",
    "    return [b,m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d31d39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Le code ci-dessous est simplement un joli packaging du code vu en cours. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def score_simple_linear_regression(df: pd.DataFrame, var: str, lr: float, n_epochs: int, label: str = 'MedHouseVal', n_repetitions: int = 100) -> tuple:\n",
    "    \"\"\"\n",
    "    Train a model `n_repetitions` time and return the average score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with the California dataset.\n",
    "    var : str\n",
    "        Variable to use as feature.\n",
    "    label : str, default 'MedHouseVal'\n",
    "        Label to use.\n",
    "    n_repetitions : int, default = 100\n",
    "        Number of repetitions for the training. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple\n",
    "        (Mean score, list of labels, list of predictions, best m, best b)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    data = df[[var, label]].values\n",
    "    \n",
    "    ms = []\n",
    "    bs = []\n",
    "    \n",
    "    for _ in range(n_repetitions):\n",
    "        train, test = train_test_split(data, test_size=0.2)\n",
    "        # Initialize m and b.\n",
    "        initial_b = np.random.rand(1) # intercept\n",
    "        initial_m = np.random.rand(1) # pente\n",
    "        \n",
    "        # Step 4: gradient descent\n",
    "        [b, m] = gradient_descent(train, initial_b, initial_m, lr, n_epochs, verbose=False)\n",
    "        preds = test[:, 0] * m + b\n",
    "        lbls = [test[i, 1] for i in range(len(test))]\n",
    "        ms.append(m)\n",
    "        bs.append(b)\n",
    "        \n",
    "        # Inversez le commentaire ci-dessous pour utiliser la méthode de sklearn.\n",
    "        #scores.append(r2_score(lbls, preds))\n",
    "        scores.append(pearson(lbls, preds))\n",
    "        \n",
    "        labels += lbls\n",
    "        predictions += list(preds)\n",
    "    \n",
    "    best_idx = scores.index(max(scores))\n",
    "    \n",
    "    return np.mean(scores), labels, predictions, ms[best_idx], bs[best_idx]\n",
    "\n",
    "def plot_regression_line(data: np.ndarray, x_name: str, y_name: str, m: float, b: float, title: str) -> plt.axes:\n",
    "    \"\"\"\n",
    "    Plot the regression line using the given `m` and `b`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Data with the variable and the label to plot. \n",
    "        Label must be in the last column.\n",
    "    x_name : str\n",
    "        Name of the column for x.\n",
    "    y_name : str\n",
    "        Name of the column for y.\n",
    "    m : float\n",
    "        m value to use for the predictions.\n",
    "    b : float\n",
    "        b value to use for the predictions.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    plt.axes\n",
    "        Matplotlib ax. \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "    data.plot.scatter(x=x_name, y=y_name, ax=ax, title=title)\n",
    "    y_pred = m * data[x_name] + b\n",
    "    ax.plot(data[x_name].values, y_pred, 'r')\n",
    "    ax.text(0.025, 0.925,\n",
    "            f'$R^2={np.round(r2_score(data[y_name].values, y_pred), 3)}$',\n",
    "            fontsize=12, transform=ax.transAxes)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c78ae5",
   "metadata": {},
   "source": [
    "**Normalisation des données et régression linéaire simple.**\n",
    "\n",
    "Si vous n'avez pas réussi à écrire une fonction **pearson()**, (de)commentez les lignes indiquées dans la fonction \"*score_simple_linear_regression()*\" ci-dessus afin d'utiliser la méthode de sklearn. \n",
    "\n",
    "\n",
    "Comme vu dans le labo précédent, il vaut souvent mieux normaliser/standardiser les données (moyenne nulle et écart-type à 1). Ça n'est pas toujours le cas et ça peut être discutable. Ici nous allons normaliser les variables indépendantes que nous voulons utiliser pour la régression linéaire simple. \n",
    "\n",
    "\n",
    "\n",
    "*Tip: n'oubliez pas que vous pouvez développer ou réduire la sortie de l'exécution d'une cellule en cliquant sur la gauche de la cellule. Comme la sortie de la cellule suivante est relativement longue, la réduire pour ne pas scroller pendant trop longtemps peut être utile!*\n",
    "\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Lisez puis exécutez le code ci-dessous. Répondez en suite aux questions. Vous êtes libres de fixer un seed si vous le désirez afin d'avoir des résultats reproductibles.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75002b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# seed \n",
    "np.random.seed(42)\n",
    "\n",
    "# Mesure du temps au début\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# On va prendre un subset du dataframe, avec sa taille on en aurait pour 1h de calcul à chaque fois.\n",
    "indices = rng.choice(np.arange(df.shape[0]), \n",
    "                     size=500,\n",
    "                     replace=False)\n",
    "subset_df = df.iloc[indices]\n",
    "\n",
    "# Standardisation\n",
    "\n",
    "# Copie de l'échantillon et normalisation des colonnes choisies (toutes sauf MedHouseVal)\n",
    "df_normalized = subset_df.copy()\n",
    "cols = subset_df.columns[df.columns != 'MedHouseVal']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_normalized[cols] = scaler.fit_transform(df_normalized[cols])\n",
    "\n",
    "variables = ['MedInc',\n",
    "             'AveRooms',\n",
    "             'Population']\n",
    "\n",
    "\n",
    "print(f\"Variables testées pour la régression linéaire simple: {variables}\") \n",
    "label = 'MedHouseVal'\n",
    "\n",
    "learning_rates = [0.5, 0.1, 0.01, 0.001]\n",
    "n_epochs = 30\n",
    "scores = {}\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"Variable {var}\")\n",
    "    scores[var] = {}\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Learning rate: {lr}\")\n",
    "        score, _, _, m, b = score_simple_linear_regression(df_normalized, var, lr, n_epochs, label=label)\n",
    "        scores[var][lr] = score\n",
    "        plot_regression_line(df_normalized, var, 'MedHouseVal', m, b, f'Plot of regression line with {var=}, {lr=}')\n",
    "        plt.show()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Exécution: {end - start} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb151a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Résumez ce qui est fait dans cette partie 2.3. Quelles fonctions sont utilisées et pourquoi ? (pas besoin de donner les détails des fonctions que vous avez déjà complété plus haut)</p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e937731-38d7-47b9-9e84-95fbe1fef7c1",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "On teste des régressions linéaires simples pour prédire MedHouseVal à partir de trois variables (MedInc, AveRooms, Population).\n",
    "Les fonctions utilisées :\n",
    "* score_simple_linear_regression : effectue la régression linéaire simple\n",
    "* plot_regression_line : trace la ligne de régression superposées aux données\n",
    "* Les autres fonctions sont celles expliquées plus haut  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdcbdc0",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>  Quel est le meilleur score que vous obtenez ? Et que signifie-t-il (qu'est-ce que $R^2$) ?</p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f2fd1",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "Le meilleur score est $R^2 = 0.436$ \n",
    "\n",
    "Le $R^2$ est le coefficient de détermination. Il permet d'évaluer l'efficacité d'un modèle de régression linéaire.\n",
    "\n",
    "Dans notre cas, cela veut dire que le modèle prédit mieux que la moyenne mais pas parfaitement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679a6ce",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>  Quels sont les risques en choisissant un learning rate trop petit ou trop grand ?</p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b4641",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "Un learning rate trop petit va amener une lente convergence, une possible stagnation et un temps de calcul élevé\n",
    "\n",
    "Un learning rate trop grand va amener une divergence et une instabilité du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb15ba",
   "metadata": {},
   "source": [
    "<a name=\"Part23pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.3: </b> Points obtenus: /12\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f16db",
   "metadata": {},
   "source": [
    "<a name=\"Part24\"></a>\n",
    "### 2.4 Régression linéaire multiple\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838b7bc",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons utiliser [la classe LinearRegression de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) qui va nous permettre de tester plusieurs groupes de variables pour créer un modèle de régression linéaire avec plusieurs variables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c13efb",
   "metadata": {},
   "source": [
    "---\n",
    "Le modèle de régression linéaire multiple peut être exprimé comme suit :\n",
    "\n",
    "$\n",
    "Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\ldots + \\beta_pX_p + \\epsilon\n",
    "$\n",
    "\n",
    "où :\n",
    "- $ Y $ est la variable dépendante,\n",
    "- $ X_1, X_2, \\ldots, X_p $ sont les variables indépendantes,\n",
    "- $ \\beta_0 $ est l'ordonnée à l'origine,\n",
    "- $ \\beta_1, \\beta_2, \\ldots, \\beta_p $ sont les coefficients ou paramètres associés à chaque variable indépendante,\n",
    "- $ \\epsilon $ est le terme d'erreur.\n",
    "\n",
    "\n",
    "\n",
    "En résumé, la régression linéaire multiple vise à modéliser la relation entre plusieurs variables indépendantes $ X_1, X_2, \\ldots, X_p $ et une variable dépendante $ Y $ en ajustant une équation linéaire aux données observées. Les coefficients $ \\beta_0, \\beta_1, \\ldots, \\beta_p $ sont estimés en utilisant des techniques telles que les moindres carrés pour minimiser la différence entre les valeurs observées et prédites de la variable dépendante.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8440a394",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Lisez puis exécutez le code ci-dessous. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(4321)\n",
    "\n",
    "# Régression linéaire avec sklearn\n",
    "\n",
    "def score_linear_regression(df: pd.DataFrame, *var: str, label: str = 'MedHouseVal', n_repetitions: int = 100):\n",
    "    \"\"\"\n",
    "    Train a model `n_repetitions` time and return the average score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with the boston dataset.\n",
    "    var : Tuple of str\n",
    "        Tuple with the variables to use as feature.\n",
    "    label : str, default 'MEDV'\n",
    "        Label to use.\n",
    "    n_repetitions : int, default = 100\n",
    "        Number of repetitions for the training. \n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    for _ in range(n_repetitions):\n",
    "        regressor = LinearRegression()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df[list(var)], df[label], test_size=0.2)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        labels.append(y_test)\n",
    "        predictions.append(regressor.predict(X_test))\n",
    "        scores.append(regressor.score(X_test, y_test)) \n",
    "        \n",
    "    return np.mean(scores), labels, predictions, regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac694f31",
   "metadata": {},
   "source": [
    "On choisit en suite quel groupes de variables nous allons utiliser pour créer des modèles linéaires. On essaie plusieurs groupes avec une ou plusieurs variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groupes = [['Latitude', 'Longitude'], \n",
    "          ['AveRooms', 'Population', 'MedInc'],\n",
    "          ['AveRooms', 'Population'], \n",
    "          ['AveRooms', 'MedInc'], \n",
    "          ['Population', 'MedInc'],\n",
    "          ['MedInc']]\n",
    "\n",
    "label = 'MedHouseVal'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf404e",
   "metadata": {},
   "source": [
    "Puis nous réalisons, à l'aide de notre fonction définie plus haut, plusieurs régression linéaires à l'aide des variables choisies. On afiche simplement le score obtenu: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for no, variables in enumerate(groupes):\n",
    "    print(\"---------------------------------\")\n",
    "    print(f'Model number {no} using {variables}')\n",
    "    score, y_true, y_pred, regressor = score_linear_regression(df_normalized, *variables, label=label)\n",
    "    \n",
    "    print(f'Score={score}')\n",
    "    print(f'Coefficients: {regressor.coef_}')\n",
    "    print(f'Intercept: {regressor.intercept_}')\n",
    "    \n",
    "    results.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05141a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quel est le meilleur score que vous obtenez ? Quel est le score (metrics) utilisé par LinearRegression() ?</p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35132052",
   "metadata": {},
   "source": [
    "*Réponse:*

Le meilleur score obtenu est de 0.4462 avec le modèle utilisant les variables ['AveRooms', 'MedInc'].
Le score utilisé par LinearRegression() de scikit-learn est le coefficient de détermination (R²). Il indique combien de la variance de la variable dépendante est expliquée par les variables indépendantes. Un R² de 1 signifie que le modèle explique parfaitement la variance, tandis qu'un R² de 0 signifie qu'il n'explique rien.",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603e892",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Que sont les coefficients et l'intercept en terme de régression ? Comment sont-ils utilisés lors d'une prédiction ? </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a9328",
   "metadata": {},
   "source": [
    "*Réponse:*

Les **coefficients** indiquent l'importance de chaque variable indépendante dans la prédiction. L'**intercept** est la valeur de la variable dépendante lorsque toutes les variables indépendantes sont à zéro. Lors d'une prédiction, on utilise la formule de régression linéaire multiple : on multiplie chaque coefficient par la valeur correspondante de la variable indépendante, on additionne ces produits et on ajoute l'intercept pour obtenir la prédiction.",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e07958",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Prenez le modèle (stocké dans la liste \"results\"), qui utilise le nombre moyen de pièces et le revenu median et faites les prédictions avec les valeurs suivantes. </p> (4 points)\n",
    "\n",
    "\n",
    "- Block Group 1: AveRooms 10, MedInc 5\n",
    "- Block Group 2: AveRooms 5, MedInc 10\n",
    "- Block Group 3: AveRooms 2, MedInc 15\n",
    "- Block Group 4: AveRooms 5, MedInc 5\n",
    "\n",
    "Pour rappel du contexte, le but du modèle est de permettre de prédire le prix median des maisons dans un nouveau block group (petite région géographique). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np
import pandas as pd

# Préparez les données
data = np.array([
    [10, 5],
    [5, 10],
    [2, 15],
    [5, 5]
])

column_names = ['AveRooms', 'MedInc']

new_data = pd.DataFrame(data, columns=column_names)

# Faites la prédiction et affichez le résultat (4 valeurs)
model = results[3]  # Modèle utilisant 'AveRooms' et 'MedInc'

predictions = model.predict(new_data)
print(predictions)
"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffecea",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Est-ce que les valeurs obtenues correspondent à ce qui était attendu (par rapport aux coefficients et à l'intercept) ? Que peut-on tirer de ces prédictions ? </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a03feb",
   "metadata": {},
   "source": [
    "*Réponse:*

Les valeurs obtenues correspondent aux prédictions attendues en utilisant les coefficients et l'intercept du modèle. Les prédictions montrent que le revenu médian a un impact significatif sur le prix médian des maisons, tandis que le nombre moyen de pièces a un effet moindre mais toujours présent.

",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aab01b",
   "metadata": {},
   "source": [
    "<a name=\"Part24pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.4: </b> Points obtenus: /10\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe439f",
   "metadata": {},
   "source": [
    "<a name=\"Part25\"></a>\n",
    "### 2.5 Conclusion\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0993f57",
   "metadata": {},
   "source": [
    "Nous avons maintenant un modèle qui prédit plus ou moins bien le prix d'une maison selon le nombre de pièces de la maison et surtout le revenu moyen des habitants du Block Group. Comme nous l'avons rapidement survolé, certaines variable (prédicteurs) peuvent être corrélées entre elles (voir [correlation heatmap](#plotC)) et cette [multicolinéarité](https://en.wikipedia.org/wiki/Multicollinearity) peut poser des problèmes. Répondez à la question suivante de manière concise. Vous êtes libre d'utiliser chatGPT ou autre IA pour vous aider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88df03",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quels risques la multicollinéarité des prédicteurs dans une régression linéaire peut-elle poser ?</p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3448ac",
   "metadata": {},
   "source": [
    "*Réponse:* 

La multicollinéarité des prédicteurs dans une régression linéaire peut poser les risques suivants :
- **Coefficients instables** : Les coefficients peuvent devenir très sensibles aux petites modifications des données, rendant les estimations peu fiables.
- **Interprétation difficile** : Il devient difficile de déterminer l'impact individuel de chaque prédicteur sur la variable dépendante.
- **Significativité réduite** : Les tests de significativité des coefficients peuvent être faussés, rendant difficile l'identification des prédicteurs réellement importants.
- **Prédictions moins précises** : La précision des prédictions peut diminuer, affectant la performance globale du modèle.

",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90625bf3",
   "metadata": {},
   "source": [
    "<a name=\"Part25pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.5: </b> Points obtenus: /2\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939f4dc",
   "metadata": {},
   "source": [
    "## 3) Tenter K-means<a name=\"Part3\"></a>\n",
    "\n",
    "[Table des matières](#toc)\n",
    "\n",
    "Dans cette partie nous allons tenter de regrouper nos données en groupes distincts qui pourrait éventuellement nous permettre d'adapter notre algorithme de prédiction des prix. Comme nous l'avons vu lors de l'analyse exploratoire, les prix médians des maisons sont bien plus élevés près des grandes villes nous pourions alors éventuellement trouver des clusters distincts par région. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772ee70",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Exécutez le code ci-dessous et jouez avec le nombre de clusters. Observez le graphique 3D correspondant et répondez aux questions.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dce2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et analyse des interties\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "X1 = df[['Latitude' , 'Longitude', 'MedHouseVal']].iloc[: , :].values\n",
    "inertia = []\n",
    "for n in range(1 , 11):\n",
    "    algorithm = (KMeans(n_clusters = n ,init='k-means++', n_init = 10 ,max_iter=300, \n",
    "                        tol=0.0001,  random_state= 111  , algorithm='elkan') )\n",
    "    algorithm.fit(X1)\n",
    "    inertia.append(algorithm.inertia_)\n",
    "    \n",
    "plt.figure(1 , figsize = (15 ,6))\n",
    "plt.plot(np.arange(1 , 11) , inertia , 'o')\n",
    "plt.plot(np.arange(1 , 11) , inertia , '-' , alpha = 0.5)\n",
    "plt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715562d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des clusters\n",
    "algorithm = (KMeans(n_clusters = 10 ,init='k-means++', n_init = 10 ,max_iter=300, \n",
    "                        tol=0.0001,  random_state= 111  , algorithm='elkan'))\n",
    "algorithm.fit(X1)\n",
    "labels1 = algorithm.labels_\n",
    "centroids1 = algorithm.cluster_centers_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du plot 3D\n",
    "df['label3'] =  labels1\n",
    "trace1 = go.Scatter3d(\n",
    "    x= df['Latitude'],\n",
    "    y= df['Longitude'],\n",
    "    z= df['MedHouseVal'],\n",
    "    mode='markers',\n",
    "     marker=dict(\n",
    "        color = df['label3'], \n",
    "        size= 2,\n",
    "        line=dict(\n",
    "            color= df['label3'],\n",
    "            width= 12\n",
    "        ),\n",
    "        opacity=0.8\n",
    "     )\n",
    ")\n",
    "data = [trace1]\n",
    "# Adjusting the axis ranges\n",
    "x_range = [df['Latitude'].min(), df['Latitude'].max()]\n",
    "y_range = [df['Longitude'].max(), df['Longitude'].min()]\n",
    "z_range = [df['MedHouseVal'].min(), df['MedHouseVal'].max()]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Clusters',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Latitude', range=x_range),  # Adjusting x-axis range\n",
    "        yaxis=dict(title='Longitude', range=y_range),  # Adjusting y-axis range\n",
    "        zaxis=dict(title='MedHouseVal', range=z_range)  # Adjusting z-axis range\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613b5cd",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Le clustering avec 2 clusters fait-il plus de sens que le clustering avec 6 clusters ? Quels clusters seraient intéressants ? Qu'observez-vous concernant les valeurs extrèmes ? Quelles variable pourrait être ajoutée au set de donnée ?</p> (5 points)\n",
    "\n",
    "Donnez une analyse des clusters observés, des possibilités et des limitations du clustering dans notre cas. Faites des phrases et répondez un maximum aux questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d5feb",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67f5b5",
   "metadata": {},
   "source": [
    "<a name=\"Part3pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 3: </b> Points obtenus: /5\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 3](#Part3) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f83ee",
   "metadata": {},
   "source": [
    "Fin\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isd",
   "language": "python",
   "name": "isd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
